---
title: "TAE - Unit 6 - Lecture 2"
author: "GT"
date: "May 20, 2016"
output: html_document
---

## Predictive Diagnosis

In this lecture, we discuss the idea of predictive analytics in medicine. Specifically, 
we introduce the idea of using clustering methods for better predicting heart attacks.

Heart attacks are a common complication of coronary heart disease, resulting from the 
interruption of blood supply to part of the heart.

Heart attack is the number one cause of death for both men and women in the United States.

About one in every four deaths is due to heart attack. A 2012 report from the American Heart 
Association estimates about 715,000 Americans have a heart attack every year.

To put this number into perspective, this means that every 20 seconds, a person
has a heart attack in the United States. 

Nearly half of these attacks occur without prior warning signs.

In fact, 250,000 Americans die of sudden cardiac death yearly, which means 680 people every 
day die of sudden cardiac death.

A heart attack has well-known symptoms, chest pain, shortness of breath, upper body pain, nausea.

The nature of heart attacks, however, makes it hard to predict, prevent, and even diagnose.

Here are some statistics.

- 25% of heart attacks are silent.
- 47% of sudden cardiac deaths occur outside hospitals, suggesting that many patients do not act
  on early warning signs.
- 27% percent of respondents to a 2005 survey recognized the symptoms and called 911 for help.

How can analytics help?

The key to helping patients is to understand the clinical characteristics of patients
in whom heart attacks was missed.

We need to better understand the patterns in a patient's diagnostic history that link to heart attack
and to predicting whether a patient is at risk for a heart attack.

We'll see, in this lecture, how analytics helps to understand patterns of heart attacks
and to provide good predictions that in turn lead to improved monitoring and taking action early
and effectively.

### The Data

Claims data offers an expansive view of the patient's health history. Specifically, claims 
data include information on demographics, medical history, and medications.

They offer insights regarding a patient's risk. And as I will demonstrate, may reveal 
indicative signals and patterns.

We'll use health insurance claims filed for about 7,000 members from January 2000
until November 2007.

We concentrated on members with the following attributes.

- At least 5 claims with coronary artery disease diagnosis 
- At least 5 claims with hypertension diagnostic codes 
- At least 100 total medical claims,
- At least 5 pharmacy claims
- Data from at least five years

These selections yield patients with a high risk of heart attack, and a reasonably rich 
medical history with continuous coverage.

Let us discuss how we aggregated this data.

The resulting data sets includes about 20 million health insurance entries, 
including individual, medical, and pharmaceutical records.

Diagnosis, procedures, and drug codes in the data set comprised tens of thousands of attributes.

The codes were aggregated into groups.

- 218 diagnosis groups, 180 procedure groups, 538 drug groups
- 46 diagnosis groups were considered by clinicians as possible risk factors for heart attacks.

Let us discuss how we view the data over time.

It is important in this study to view the medical records chronologically, and to represent 
a patient's diagnosis profile over time.

So we record the cost and number of medical claims and hospital visits by a diagnosis.

All the observations we have span over five years of data. They were split into 21 periods,
each 90 days in length.

We examine nine months of diagnostic history, leading up to heart attack or no heart attack event,
and align the data to make observations that are date-independent, while preserving the order of events.

We recorded the diagnostic history in three periods.

- 0 to 3 months before the event
- 3 to 6 months before the event
- 6 to 9 months before the event

What was the target variable we were trying to predict?

The target prediction variable is the occurrence of a heart attack.

We define this from a combination of several claims. 

Namely, diagnosis of a heart attack, alongside a trip to the emergency room,
followed by subsequent hospitalization.

Only considering heart attack diagnosis that are associated with a visit to the emergency room,
and following hospitalization helps ensure that the target outcome is in fact a heart attack
event.

The target variable is binary. It is denoted by plus 1 or minus 1 for the occurrence or
non-occurrence of a heart attack in the targeted period of 90 days.

How is the data organized?

There were 147 variables.


Variable  |   Description
--------- | ---------------------------------------------------
     1    | Patient's identification number
     2    | Gender
    3-49  | Diagnosis group counts 9 months before heart attack
    50    | Total cost 9 months before heart attack
   51-97  | Diagnosis group counts 6 months before heart attack
    98    | Total cost 6 months before heart attack
  99-145  | Diagnosis group counts 3 months before heart attack
    146   | Total cost 3 months before heart attack
    147   | Yes/No heart attack

Cost of medical care is a good summary of a person's health.

In our database, the total cost of medical care in the three 90 day periods preceding the 
heart attack target event ranged from $0 to $636,000 and approximately 70% of the overall 
cost was generated by only 11% of the population.

This means that the highest patients with high medical expenses are a very small proportion
of the data, and could skew our final results. 

According to the American Medical Association, only 10% of individuals have projected medical 
expenses of approximately $10,000 or greater per year, which is more than four times greater
than the average projected medical expenses of $2,400 per year.

To lessen the effects of these high-cost outliers, we divided the data into different cost buckets,
based on the findings of the American Medical Association.

We did not want to have too many cost bins because the size of the data set.

Bucket | Cost Range | % Data | Members | % with Heart Attack
------ | ---------- | ------ | ------- | -------------------
   1   |    < $2K   | 67.56  |   4416  |    36.14 
   2   | $2K - $10K | 21.56  |   1409  |    43.22
   3   |   > $10K   | 10.88  |    711  |    38.12


Please note that the majority of patients, 4,400 out of 6,500, or 67.5% of all patients fell
into the first bucket of low expenses.

### Predicting Heart Attacks using Clustering

The Random Forest algorithm is known for its attractive property of detecting
variable interactions and excellent performance as a learning algorithm.

For this reason, we're selecting the Random Forest algorithm as a benchmark,
initially, we randomly partitioned the full data set into two separate parts,
where the split was 50-50, and the partitioning was done evenly within each
cost bin.

The first part, the training set, was used to develop the method.
The second part, the test set, was used to evaluate the model's performance.

The table reports the accuracy of the Random Forest algorithm on each 
of the three buckets.

Bucket | Random Forest
------ | -------------
   1   |     49.63%
   2   |     55.99%
   3   |     58.31%


Let us now introduce the idea of clustering.

Patients in each bucket may have different characteristics. 

For this reason, we create clusters for each cost bucket and make predictions
for each cluster using the Random Forest algorithm.

Clustering is mostly used in the absence of a target variable to search for
relationships among input variables or to organize data into meaningful
groups.

In this study, although the target variable is well-defined as a heart attack
or not a heart attack, there are many different trajectories that are
associated with the target.

There's not one set pattern of health or diagnostic combination that leads a
person to heart attack. Instead, we'll show that there are many different
dynamic health patterns and time series diagnostic relations preceding a heart
attack.

The clustering methods we used for the analysis, as an alternative to
hierarchical clustering, were spectral clustering and k-means clustering.

We focus, in the lecture, on the k-means clustering.

k-Means Clustering Algorithm

1. Specify desidered number of clusters k
2. Randomly assign each data point to  cluster
3. Compute cluster centroids
4. Re-assign each point to the closest cluster centroid
5. Re-compute cluster centroids
6. Repeate 4 and 5 until no improvement is made

Let us illustrate the k-means algorithm in action.

We specify the desired number of clusters k. In this case, we use k=2.
We then randomly assign each data point to a cluster. In this case, we have
the three points in red, and the two points in black. We then compute the 
cluster centroids, indicated by the red x and the grey x. We re-assign each
point to the closest cluster centroid, and now you observe that this point 
changes from a red to a grey. We re-compute the cluster centroids, and we
repeat the previous steps, 4 and 5 until no improvement is made. We observe
that, in this case, the k-means clustering is done, and this is our final
clustering.

Let us discuss some practical considerations.

The number of clusters k can be selected from previous knowledge or by simply 
experimenting.

We can strategically select an initial partition of points into clusters if we
have some knowledge of the data.

We can also run the algorithm several times with different random starting
points.

So how do we measure performance?

After we construct the clusters in the training set, we assign new
observations to clusters by proximity to the centroid of each cluster.

We measure performance by recording the average performance rate in each
cluster. 

Let us now discuss the performance of the clustering
methods.

We perform clustering on each bucket using k=10 clusters.

In the table we record the average prediction rate of each cost bucket.

Cost Bucket | Random Forest without Clustering | Random Forest with Clustering
----------- | -------------------------------- | -----------------------------
       1    |                49.63%            |               64.75%
       2    |                55.99%            |               72.93%
       3    |                58.31%            |               78.25%

We observe a very visible improvement.

### Understanding Cluster Patterns

Let us see what we learned about the patterns that emerge.

We will show that the clusters are interpretable and reveal unique patterns 
of diagnostic history among the population.

We selected six patterns to present in this lecture:

Cost Bucket 2  | Pattern
-------------- | ------------------------------------- 
Cluster 1      | Chest Pain (3 months)
Cluster 6      | Coronary Artery Diseases (3 months)
Cluster 7      | Chronic Obstructive Pulmonary Disease



Cost Bucket 3  | Pattern
-------------- | ----------------------------------------
Cluster 4      | Anemia(3, 6, 9 months)
Cluster 5      | Hypertension and Cerebrovascular Disease
Cluster 10     | Diabetes (3, 6, 9 months)


The first pattern shows the occurrence of chest pain three months before
the heart attack.

The next pattern reveals an increasing occurrence of chronic obstructive
pulmonary disease, COPD, for short. Patients from Cluster 7 in Bucket 2
have regular doctor visits for COPD.

The next pattern shows gradually increasing occurrence of anemia.

The final pattern shows the occurrence of diabetes as a pattern for 
heart attacks. It is well known that both types 1 and 2 diabetes are
associated with accelerated atherosclerosis, one of the main causes of 
heart attacks, that is.

Well known diagnoses associated with heart attacks, such as diabetes,
hypertension, and hyperlipidemia, characterize many of the patterns of the
consistency of care throughout all of the cost buckets and clustering
models.

### The Analytics Edge

What is the impact of clustering?

Clustering members within each cost bucket yielded better predictions for
heart attacks within clusters.

Grouping patients in clusters exhibits temporal diagnostic patterns within
nine months of a heart attack.

These patterns can be incorporated in the diagnostic rules for heart attacks.

The approach shows that using analytics for early heart failure detection
through pattern recognition can lead to interesting new insights.

The findings here are reinforced by results from our research. IBM, Sutter
Health, and Geisinger Health Systems partnered in 2009 to research analytics
tools in view of early detection.

Steve Steinhubl, a cardiologist from Geisinger, wrote, "our early research
showed the signs and symptoms of heart failure in patients are often
documented years before diagnosis. The pattern of documentation can offer
clinically useful signals for early detection of this deadly disease."