---
title: "TAE - Unit 4 - Recitation"
author: "GT"
date: "10 mai 2016"
output: html_document
---

## Location, Location, Location

In this recitation, we will be looking at regression trees, and applying them to data related
to house prices and locations.

### Boston Housing Data

In real estate, there is a famous saying that the most important thing is location, location, location.

Boston is the capital of the state of Massachusetts, USA. It was first settled in 1630, and in the
greater Boston area there are about 5 million people. The area features some of the highest population
densities in America.

In this recitation, we will be talking about Boston in a sense of the greater Boston area.
Over the greater Boston area, the nature of the housing varies widely.

This data comes from a paper, "Hedonic Housing Prices and the Demand for Clean Air," which
has been cited more than 1,000 times. This paper was written on a relationship between house
prices and clean air in the late 1970s by David Harrison of Harvard and Daniel Rubinfeld
of the University of Michigan.

The data set is widely used to evaluate algorithms of a nature we discuss in this class.

In the lecture, we mostly discuss *classification trees* with the output as a factor or a category.

Trees can also be used for regression tasks. The output at each leaf of a tree is no longer a category, 
but a number.

Just like classification trees, regression trees can capture nonlinearities that linear regression can't.

So what does that mean?

Well, with classification trees we report the average outcome at each leaf of our tree.

For example, if the outcome is true 15 times, and false 5 times, the value at that leaf of a tree would be
15/(15+5)=0.75. Now, if we use the default threshold of 0.5, we would say the value at this leaf is true.

With regression trees, we now have continuous variables. We report the average of the values at that leaf.

So suppose we had the values 3, 4, and 5 at one of the leaves of our trees. Well, we just take the average
of these numbers, which is 4, and that is what we report.

That might be a bit confusing so let's look at a picture.

```
  ^
  |   xxx
8 |  xxxx
  |   xx x                  x
6 |                          x xx x
  |                        x xxx
4 |           xxx
  |           xx x
2 |          x x x
  |
  |--------------------------------->
        10         20         30
```

So if we fit a linear regression to this data set, it does not do very well on this data set.

However, we can notice that the data lies in three different groups.
If we draw these lines here, we see x is either less than 10, between 10 and 20, or greater then 20,
and there is very different behavior in each group.

Regression trees can fit that kind of thing exactly. So the splits would be x is less than or equal to 10,
take the average of those values. x is between 10 and 20, take the average of those values. x is between 20 
and 30, take the average of those values.

We see that regression trees can fit some kinds of data very well that linear regression completely fails on.

In this recitation, we will explore the data set with the aid of trees. We will compare linear regression
with regression trees. We will discuss what the cp parameter means that we brought up when we did 
cross-validation in the lecture, and we will apply cross-validation to regression trees.

### The Data

- Each entry of this data set corresponds to a census **tract**, a statistical division of the area that
is used by researchers to break down towns and cities. 
- There will usually be multiple census tracts per **town**.
- **LON** and **LAT** are the longitude and latitude of the center of the census tract.
- **MEDV** is the median value of owner-occupied homes, measured in thousands of dollars.
- **CRIM** is the per capita crime rate. 
- **ZN** is related to how much of the land is zoned for large residential properties.
- **INDUS** is the proportion of the area used for industry.
- **CHAS** is 1 if a census tract is next to the Charles River.
- **NOX** is the concentration of nitrous oxides in the air, a measure of air pollution.
- **RM** is the average number of rooms per dwelling.
- **AGE** is the proportion of owner-occupied units built before 1940.
- **DIS** is a measure of how far the tract is from centers of employment in Boston.
- **RAD** is a measure of closeness to important highways.
- **TAX** is the property tax per $10,000 of value.
- **PTRATIO** is the pupil to teacher ratio by town.

So let's begin to analyze our data set with R. First of all, we'll load the data set into the Boston variable.
If we look at the structure of the Boston data set,we can see all the variables we talked about before.

```{r}
boston = read.csv("boston.csv")
str(boston)
```

There are 506 observations corresponding to 506 census tracts in the Greater Boston area.

We are interested in building a model initiallyof how prices vary by location across a region.

So let's first see how the points are laid out.Using the plot commands, we can plot the latitude and longitude
of each of our census tracts.

```{r}
plot(boston$LON, boston$LAT)
```

This picture might be a little bit meaningless to you if you're not familiar with the Massachusetts-Boston area,
but I can tell you that the dense central core of points corresponds to Boston city, Cambridge city, and 
other close urban cities.

So we want to show all the points that lie along the Charles River in a different color.
We have a variable, CHAS, that tells us if a point is on the Charles River or not.

```{r}
plot(boston$LON, boston$LAT)
points(boston$LON[boston$CHAS==1],boston$LAT[boston$CHAS==1], col="blue", pch=19)
```

So by running this command, you see we have some blue dots in our plot now. These are the census
tracts that lie along the Charles River. But maybe it's still a little bit confusing, and you'd like
to know where MIT is in this picture.

The census tract MIT is tract 3531. So let's plot that.

```{r}
plot(boston$LON, boston$LAT)
points(boston$LON[boston$CHAS==1],boston$LAT[boston$CHAS==1], col="blue", pch=19)
points(boston$LON[boston$TRACT==3531],boston$LAT[boston$TRACT==3531], col="red", pch=19)
```

Can you see it on the little picture? It's a little red dot, right in the middle.

What other things can we do?

Well, this data set was originally constructed to investigate questions about how air pollution 
affects prices. So the air pollution variable is this NOX variable. Let's have a look at a distribution
of NOX.

```{r}
summary(boston$NOX)
```

So we see that the minimum value is 0.385, the maximum value is 0.87 and t
he median and the mean are about 0.53, 0.55.
So let's just use the value of 0.55, as it's kind of in the middle. And we'll look at just the census
tracts that have above-average pollution.

```{r}
plot(boston$LON, boston$LAT)
points(boston$LON[boston$CHAS==1],boston$LAT[boston$CHAS==1], col="blue", pch=19)
points(boston$LON[boston$NOX>=0.55], boston$LAT[boston$NOX>=0.55], col="green", pch=19)
points(boston$LON[boston$TRACT==3531],boston$LAT[boston$TRACT==3531], col="red", pch=19)
```


So those are all the points that have got above-average pollution. Looks like my office is right
in the middle. Now it kind of makes sense, though, because that's the dense urban core of Boston.
If you think of anywhere where pollution would be, you'd think it'd be where the most cars and the 
most people are.

Now, before we do anything more, we should probably look at how prices vary over the area as well.
If we look at the distribution of the housing prices (boston$MEDV),

```{r}
summary(boston$MEDV)
```

we see that the minimum price, units are thousands of dollars, is around five,
the maximum is around 50.

So let's plot again only the above-average price points.

```{r}
plot(boston$LON, boston$LAT)
points(boston$LON[boston$MEDV>=21.2],boston$LAT[boston$MEDV>=21.2],col="red", pch=19)
```

So what we see now are all the census tracts with above-average housing prices.
As you can see, it's definitely not simple.

The census tracts of above-average and below-average are mixed in between each other.
So there's definitely some structure to it, but it's certainly not simple in relation
to latitude and longitude at least.

### Geographical Predictions

We saw that the house prices were distributed over the area in an interesting way,
certainly not the kind of linear way. And we wouldn't necessarily expect linear regression
to do very well at predicting house price, just given latitude and longitude.

We can kind of develop that intuition more by plotting the relationship between 
latitude and house prices or the longitude and the house prices. They look pretty nonlinear.

```{r}
plot(boston$LAT, boston$MEDV)
plot(boston$LON, boston$MEDV)
```

So, we'll try fitting a linear regression anyway. And we'll use the lm command, linear model,
to predict house prices based on latitude and longitude using the boston data set.

```{r}
latlonlm = lm(MEDV ~ LAT + LON, data=boston)
summary(latlonlm)
```

If we take a look at our linear regression, we see the R-squared is around 0.1, which is not 
great. The latitude is not significant, which means the north-south differences aren't
going to be really used at all. Longitude is significant, and it's negative.
Which we can interpret as, as we go towards the ocean, towards the east, house prices decrease 
linearly.

So this all seems kind of unlikely, but let's work with it.

So let's see how this linear regression model looks on a plot.

```{r}
plot(boston$LON, boston$LAT)
points(boston$LON[boston$MEDV>=21.2],boston$LAT[boston$MEDV>=21.2],col="red", pch=19)
```

Now, the question we're going to ask, and then plot, is what does the linear regression model
think is above median. So we could just do this pretty easily.

We have latlonlm$fitted.values and this is what the linear regression model predicts for each 
of the 506 census tracts.

```{r}
head(latlonlm$fitted.values,20)
```

So we'll plot these on top. If we use the dots again, we'll cover up the red dots
and cover up some of the black dots. What we won't be able to see is where
the red dots and the blue dots match up. It turns out that you can actually
pass in characters to this PCH option.

```{r}
plot(boston$LON, boston$LAT)
points(boston$LON[boston$MEDV>=21.2],boston$LAT[boston$MEDV>=21.2],col="red", pch=19)
points(boston$LON[latlonlm$fitted.values>=21.2],boston$LAT[latlonlm$fitted.values>=21.2],col="blue", pch="$")
```

So, the linear regression model has plotted a dollar sign for every time it thinks the census
tract is above median value. And you can see that, indeed, it's almost as you can see the sharp line
that the linear regression defines.

And how it's pretty much vertical, because remember before, the latitude variable
was not very significant in the regression. So that's interesting and pretty wrong.

One thing that really stands out is how it says Boston is mostly above median. Even  
we saw it right from the start, there's a big non-red spot, right in the middle of Boston, 
where the house prices were below the median.

So the linear regression model isn't really doing a good job. And it's completely ignored 
everything to the right side of the picture.

### Regression Trees

Let's see how regression trees do. We'll first load the rpart library and also load the rpart 
plotting library.

```{r}
library(rpart)
library(rpart.plot)
```

We build a regression tree in the same way we would build a classification tree, using the 
rpart command. We predict MEDV as a function of latitude and longitude, using the boston dataset.

```{r}
latlontree = rpart(MEDV ~ LAT + LON, data=boston)
prp(latlontree)
```

In the plot the tree using the prp command, which is defined in rpart.plot, we can see it 
makes a lot of splits and is a little bit hard to interpret.
But the important thing is to look at the leaves.

In a classification tree, the leaves would be the classification we assign that these splits
would apply to.

But in regression trees, we instead predict the number. That number is the average of the median house
prices in that bucket or leaf.

We'll plot again the latitude of the points. And we'll again plot the points with above median 
prices. Then we want to predict what the tree thinks is above median, just like we did with 
linear regression. So we'll say the fitted values we can get from using the predict command 
on the tree we just built.

```{r}
plot(boston$LON, boston$LAT)
points(boston$LON[boston$MEDV>=21.2],boston$LAT[boston$MEDV>=21.2],col="red", pch=19)
fittedvalues = predict(latlontree)
points(boston$LON[fittedvalues>=21.2],boston$LAT[fittedvalues>=21.2],col="blue", pch="$")
```

Now we see that we've done a much better job than linear regression was able to do.
We've correctly left the low value area in Boston and below out, and we've correctly
managed to classify some of those points in the bottom right and top right.

We're still making mistakes, but we're able to make a nonlinear prediction on latitude and longitude.

So that's interesting, but the tree was very complicated. Maybe it's drastically overfitting.

Can we get most of this effect with a much simpler tree? We can.

We would just change the minbucket size. So let's build a new tree.

```{r}
latlontree = rpart(MEDV ~ LAT + LON, data=boston, minbucket=50)
plot(latlontree)
text(latlontree)
```

And we see we have far fewer splits, and it's far more interpretable.

The first split says if the longitude is greater than or equal to negative 71.07,
so if you're on the right side of the picture.

So the left-hand side of the tree corresponds to the right-hand side of the map.
And the right side of the tree corresponds to the left side of the map.

Let's see what it means visually. So we'll remember these values, and we'll
plot the longitude and latitude again.

```{r}
plot(boston$LON, boston$LAT)
# first split was on longitude = -71.07
abline(v=-71.07)
```

It corresponds to being on either the left or right-hand side of this tree.

We'll focus on the lowest price prediction, which is in the bottom left corner of the tree,
right down at the bottom left after all those splits. So that's where we want to get to.

So let's plot again the points.

```{r}
plot(boston$LON, boston$LAT)
# first split was on longitude = -71.07
abline(v=-71.07)
# next split on latitude = 42.21, Charles River
abline(h=42.21)
# final split on latitude = 42.17
abline(h=42.17)
```

And now that's interesting. If we look at the right side of the middle of the three
rectangles on the right side, that is the bucket we were predicting. And it corresponds to 
the South Boston low price area we saw before. So maybe we can make that more clear by plotting, now,
the high value prices.

```{r}
plot(boston$LON, boston$LAT)
abline(v=-71.07)
abline(h=42.21)
abline(h=42.17)
points(boston$LON[boston$MEDV>=21.2],boston$LAT[boston$MEDV>=21.2],col="red", pch=19)
```

So this makes it even more clear.

We've correctly shown how the regression tree carves out that rectangle in the bottom of Boston
and says that is a low value area. So that's actually very interesting. It's shown us something 
that regression trees can do that we would never expect linear regression to be able to do.

So the question we're going to answer is given that regression trees can do these fancy things
with latitude and longitude, is it actually going to help us to be able to build a predictive model,
predicting house prices? Well, we'll have to see.

